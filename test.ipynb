{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def load_pickle(path):\n",
    "    with open(path,'rb') as file:\n",
    "        data=pickle.load(file)\n",
    "    return data\n",
    "data_path = r'C:\\Users\\chen\\Desktop\\IPO_info\\万凯新材料股份有限公司\\info.pkl'\n",
    "\n",
    "def save_obj(obj, directory,filename):\n",
    "    with open(directory +'/'+filename + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import json\n",
    "sql_dict = {'info':'SH_XM_LB',\n",
    "            'release':'GP_GPZCZ_SHXXPL',\n",
    "            'status':'GP_GPZCZ_XMDTZTTLB',\n",
    "            'result':'GP_GPZCZ_SSWHYGGJG',\n",
    "            'res':'GP_GPZCZ_XMDTZTYYLB'}\n",
    "\n",
    "    \n",
    "headers = {'header':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.141 Safari/537.36',\n",
    "           'referer': 'https://kcb.sse.com.cn/',\n",
    "           'Accept': '*/*',\n",
    "           'Accept-Encoding': 'gzip, deflate, br',\n",
    "           'Accept-Language': 'zh-CN,zh;q=0.9',\n",
    "           'Connection': 'keep-alive',\n",
    "           'Cookie': 'JSESSIONID=C2EE2264D8056DC8BF3AB0DC23D26171',\n",
    "           'Host': 'query.sse.com.cn'}\n",
    "\n",
    "def url_parser(stockAidotNum,sqltype):\n",
    "    base_url = 'https://query.sse.com.cn/'\n",
    "    url = base_url + 'commonSoaQuery.do?' + 'jsonCallBack=jsonpCallback3373161' '&sqlId=' +sql_dict[sqltype] + '&stockAuditNum=' + stockAidotNum \n",
    "    return url\n",
    "\n",
    "def jsonp_parser(jsonp_str):\n",
    "    try:\n",
    "        return re.search('^[^(]*?\\((.*)\\)[^)]*$', jsonp_str).group(1)\n",
    "    except:\n",
    "        raise ValueError('Invalid JSONP')\n",
    "\n",
    "def data_getter(stockAidotNum):\n",
    "    stock_allInfo = {}\n",
    "    for sqltype in ['info','status','release','result','res']:\n",
    "        url = url_parser(stockAidotNum,sqltype)\n",
    "        rs = requests.get(url,headers=headers)\n",
    "        raw_data = jsonp_parser(rs.text)\n",
    "        data = json.loads(raw_data)['pageHelp']['data']\n",
    "        stock_allInfo[sqltype] = data\n",
    "    return stock_allInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sh_data = data_getter('549')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.1878847502431651"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "import random\n",
    "random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ----------------Test Environment-------------------\n",
    "import requests\n",
    "import re\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.141 Safari/537.36',}\n",
    "        #    'Accept': '*/*',\n",
    "        #    'Accept-Encoding': 'gzip, deflate',\n",
    "        #    'Accept-Language': 'zh-CN,zh;q=0.9',\n",
    "        #    'Connection': 'keep-alive',\n",
    "        #    'Host': 'listing.szse.cn'}\n",
    "import urllib.parse as urlparse\n",
    "from urllib.parse import urlencode\n",
    "def index_getter(projtype):\n",
    "    if projtype == 'ipo':\n",
    "        biztype = 1\n",
    "    elif projtype == 'refinance':\n",
    "        biztype = 2\n",
    "    elif projtype == 'reproperty':\n",
    "        biztype = 3 \n",
    "    else:\n",
    "        print(\"Input error! Please choose the correct type of data\")\n",
    "        return\n",
    "\n",
    "    params = {'bizType':biztype, 'random':random.random(),'pageIndex':0,'pageSize':1000}\n",
    "    base_url = 'http://listing.szse.cn/api/ras/projectrends/query?'\n",
    "    projList_url = base_url + urlencode(params)\n",
    "\n",
    "    r = requests.get(projList_url,headers=headers)\n",
    "    index_list = json.loads(r.text)\n",
    "    #save_obj(index_list['data'], os.getcwd()+'\\\\'+'sz_index'+'_'+projtype)\n",
    "    return index_list['data']\n",
    "\n",
    "def data_getter(prjid):\n",
    "    base_url = 'http://listing.szse.cn/api/ras/projectrends/details?id='\n",
    "    stock_url = base_url + str(prjid)\n",
    "    r = requests.get(stock_url,headers=headers)\n",
    "    stockInfo = json.loads(r.text)['data']\n",
    "    base_path = os.getcwd() \n",
    "    directory = base_path + '\\\\' + stockInfo['cmpnm']\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    # save_obj(stockInfo,directory+'\\\\'+'sz_info')\n",
    "    return stockInfo\n",
    "\n",
    "def file_getter(stockInfo):\n",
    "    base_path = os.getcwd() \n",
    "    directory = base_path + '\\\\' + stockInfo['cmpnm']\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    response = stockInfo['enquiryResponseAttachment']\n",
    "    disclosure = stockInfo['disclosureMaterials']\n",
    "    base_url = 'http://reportdocs.static.szse.cn'\n",
    "    for prj in disclosure:\n",
    "        filePath = prj['dfpth']\n",
    "        filename = directory + '\\\\'+ prj['dfnm']\n",
    "        download_url = base_url + filePath\n",
    "        time.sleep(random.randint(1, 3))\n",
    "        r = requests.get(download_url,headers=headers)\n",
    "        with open(filename,'wb') as f:\n",
    "            f.write(r.content)\n",
    "\n",
    "def save_obj(obj, directory):\n",
    "    with open(directory + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(directory ):\n",
    "    with open( directory + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "proj_list = index_getter('reproperty')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stockInfo = data_getter(proj_list[0]['prjid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "# 上海证券交易所-科创板股票审核网\n",
    "\n",
    "\n",
    "IPO_sqlId = {'info':'SH_XM_LB',\n",
    "            'release':'GP_GPZCZ_SHXXPL',\n",
    "            'status':'GP_GPZCZ_XMDTZTTLB',\n",
    "            'result':'GP_GPZCZ_SSWHYGGJG',\n",
    "            'res':'GP_GPZCZ_XMDTZTYYLB'}\n",
    "\n",
    "refinance_sqlId = {'info':'GP_BGCZ_XMLB',\n",
    "                    'release':'GP_BGCZ_SSWHYGGJG',\n",
    "                    'status':'GP_BGCZ_XMDTZTTLB',\n",
    "                    'result':'',\n",
    "                    'res':''}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "reproperty_sqlId = {'status':'GP_ZRZ_XMDTZTTLB',\n",
    "                    'release':'GP_ZRZ_GGJG',\n",
    "                    'result':'',\n",
    "                    'res':'GP_ZRZ_XMZTYYLB',\n",
    "                    'info':'GP_ZRZ_XMLB'}\n",
    "\n",
    "\n",
    "    \n",
    "headers = {'header':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.141 Safari/537.36',\n",
    "           'referer': 'https://kcb.sse.com.cn/',\n",
    "           'Accept': '*/*',\n",
    "           'Accept-Encoding': 'gzip, deflate, br',\n",
    "           'Accept-Language': 'zh-CN,zh;q=0.9',\n",
    "           'Connection': 'keep-alive',\n",
    "           'Cookie': 'JSESSIONID=A53F3AFE1C4FC9029CDF0AB8305EC4D0',\n",
    "           'Host': 'query.sse.com.cn'}\n",
    "\n",
    "base_url = 'https://query.sse.com.cn/'\n",
    "def url_parser(stockAidotNum,sqltype,projtype):\n",
    "    if projtype == 'ipo':\n",
    "        sqlId = IPO_sqlId[sqltype]\n",
    "    elif projtype == 'refinance':\n",
    "        sqlId = refinance_sqlId[sqltype]\n",
    "\n",
    "    elif projtype == 'reproperty':\n",
    "        sqlId = reproperty_sqlId[sqltype]\n",
    "    if sqlId == '':\n",
    "        return ''\n",
    "    else:\n",
    "        url = base_url + 'commonSoaQuery.do?' + 'jsonCallBack=jsonpCallback28511843' '&sqlId=' + sqlId + '&stockAuditNum=' + stockAidotNum \n",
    "        return url\n",
    "\n",
    "def jsonp_parser(jsonp_str):\n",
    "    try:\n",
    "        return re.search('^[^(]*?\\((.*)\\)[^)]*$', jsonp_str).group(1)\n",
    "    except:\n",
    "        raise ValueError('Invalid JSONP')\n",
    "\n",
    "def data_getter(stockAidotNum,projtype):\n",
    "    base_path = os.getcwd() \n",
    "    \n",
    "\n",
    "    stock_allInfo = {}\n",
    "    for sqltype in ['info','status','release','result','res']:\n",
    "\n",
    "        url = url_parser(stockAidotNum,sqltype,projtype)\n",
    "        if url != '':\n",
    "            rs = requests.get(url,headers=headers)\n",
    "            raw_data = jsonp_parser(rs.text)\n",
    "            data = json.loads(raw_data)['pageHelp']['data']\n",
    "            stock_allInfo[sqltype] = data\n",
    "        else:\n",
    "            stock_allInfo[sqltype] = ''\n",
    "    # directory = base_path+ '\\\\'+stock_allInfo['info'][0]['stockAuditName']\n",
    "    # if not os.path.exists(directory):\n",
    "    #     os.makedirs(directory)\n",
    "    # save_obj(stock_allInfo,directory+'\\\\'+'info')\n",
    "    return stock_allInfo\n",
    "\n",
    "def index_getter(projtype):\n",
    "    if projtype == 'ipo':\n",
    "        index_url = 'https://query.sse.com.cn/statusAction.do?jsonCallBack=jsonpCallback47570&isPagination=true&sqlId=SH_XM_LB&pageHelp.pageSize=1000&offerType=&commitiResult=&registeResult=&csrcCode=&currStatus=&order=updateDate%7Cdesc&keyword=&auditApplyDateBegin=&auditApplyDateEnd=&_=1611139628341'\n",
    "    elif projtype == 'refinance':\n",
    "        index_url = 'https://query.sse.com.cn/bgczStatusAction.do?jsonCallBack=jsonpCallback52431&isPagination=true&sqlId=GP_BGCZ_XMLB&pageHelp.pageSize=1000&offerType=&commitiResult=&registeResult=&csrcCode=&currStatus=&order=updateDate%7Cdesc&keyword=&auditApplyDateBegin=&auditApplyDateEnd=&_=1611139628341'\n",
    "    elif projtype == 'reproperty':\n",
    "        index_url = 'https://query.sse.com.cn/zrzStatusAction.do?jsonCallBack=jsonpCallback89527&isPagination=true&sqlId=GP_ZRZ_XMLB&pageHelp.pageSize=1000&offerType=&commitiResult=&registeResult=&csrcCode=&currStatus=&order=updateDate%7Cdesc&keyword=&auditApplyDateBegin=&auditApplyDateEnd=&_=1611139628341'\n",
    "    \n",
    "\n",
    "    r = requests.get(index_url, headers=headers)\n",
    "\n",
    "    js = jsonp_parser(r.text)\n",
    "    index_list = json.loads(js)['result']\n",
    "\n",
    "    save_obj(index_list, os.getcwd() + '\\\\' + 'sh_index'+'_'+projtype)\n",
    "    return index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa =index_getter('reproperty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'https://query.sse.com.cn/commonSoaQuery.do?jsonCallBack=jsonpCallback28511843&sqlId=GP_ZTZXMLB&stockAuditNum=1000004'"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "data_getter('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'jsonCallBack': 'jsonpCallback28511843',\n",
       " 'success': 'false',\n",
       " 'errorMsg': '找不到配置数据',\n",
       " 'errorType': 'ExceptionInterceptor'}"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sh_process(raw_data):\n",
    "    cleaned_dict = {}\n",
    "    # temp = json.loads(raw_data['pjdot'])\n",
    "    name_list = ['已受理','已问询','上市委会议','提交注册','注册生效']\n",
    "    milestone =[]\n",
    "\n",
    "    for st in raw_data['status']:\n",
    "        commit_result = '通过' if st['commitiResult'] == 1 else ''\n",
    "        temp_dict= {'status':name_list[st['auditStatus']-1],\n",
    "                    'date':st['publishDate'],\n",
    "                    'result':commit_result}\n",
    "        milestone.append(temp_dict)\n",
    "\n",
    "    info = raw_data['info'][0]\n",
    "    sx = info['intermediary'][0]['i_person']\n",
    "    k = [ssx['i_p_personName'] for ssx in sx if ssx['i_p_jobType']==22 or ssx['i_p_jobType']==23]\n",
    "    sprrep = ', '.join(k)\n",
    "    sx = info['intermediary'][1]['i_person']\n",
    "    k = [ssx['i_p_personName'] for ssx in sx if ssx['i_p_jobType']==32 or ssx['i_p_jobType']==33]\n",
    "    acctsgnt = ', '.join(k)\n",
    "    sx = info['intermediary'][2]['i_person']\n",
    "    k = [ssx['i_p_personName'] for ssx in sx if ssx['i_p_jobType']==42 or ssx['i_p_jobType']==43]\n",
    "    lglsgnt = ', '.join(k)\n",
    "    sx = info['intermediary'][3]['i_person']\n",
    "    k = [ssx['i_p_personName'] for ssx in sx if ssx['i_p_jobType']==52 or ssx['i_p_jobType']==53]\n",
    "    evalsgnt = ', '.join(k)\n",
    "    # clean up info \n",
    "    cleaned_dict['baseInfo'] = {'projID':info['stockAuditNum'],                        # 项目id\n",
    "            'cmpName':info['stockIssuer'][0]['s_issueCompanyFullName'],                       # 公司名称\n",
    "            'cmpAbbrname':info['stockIssuer'][0]['s_issueCompanyAbbrName'],                   # 公司简称\n",
    "            'projType':'IPO',                      # 项目类型\n",
    "            'currStatus':name_list[info['currStatus']-1],                    # 审核状态\n",
    "            'region':info['stockIssuer'][0]['s_province'],                        # 所属地区\n",
    "            'csrcCode':info['stockIssuer'][0]['s_csrcCodeDesc'],                      # 所属行业\n",
    "            'acptDate':raw_data['status'][0]['publishDate'],                      # 受理日期\n",
    "            'updtDate':raw_data['status'][-1]['publishDate'],                      # 更新日期\n",
    "            'issueAmount':info['planIssueCapital'],                   # 融资金额\n",
    "            'sprInst':info['intermediary'][0]['i_intermediaryName'],                       # 保荐机构\n",
    "            'sprInstAbbr':info['intermediary'][0]['i_intermediaryAbbrName'],                   # 保荐机构简称\n",
    "            'sprRep':sprrep,                        # 保荐代表人\n",
    "            'acctFirm':info['intermediary'][1]['i_intermediaryName'],                      # 会计师事务所\n",
    "            'acctSgnt':acctsgnt,                      # 签字会计师\n",
    "            'lawFirm':info['intermediary'][2]['i_intermediaryName'],                       # 律师事务所\n",
    "            'lglSgnt':lglsgnt,                       # 签字律师\n",
    "            'evalSgnt':info['intermediary'][3]['i_intermediaryName'],                      # 签字评估师\n",
    "            'evalInst':evalsgnt,                      # 评估机构\n",
    "            'projMilestone':milestone,      # 项目里程碑\n",
    "            'auditMarket':'上海证券交易所'}                   # 所属交易所\n",
    "\n",
    "    # # clean up file\n",
    "    # indicator = {'disclosureMaterials':'disclosureMaterial',\n",
    "    #             'enquiryResponseAttachment':'responseAttachment',\n",
    "    #             'meetingConclusionAttachment':'meetingAttachment',\n",
    "    #             'terminationNoticeAttachment':'terminationAttachment',\n",
    "    #             'registrationResultAttachment':'registrationAttachment'}\n",
    "\n",
    "    # for key,value in indicator.items():\n",
    "    #     material =[]\n",
    "    #     for file in raw_data[key]:\n",
    "    #         temp_dict =  { 'fname':file['dfnm'],           #  文件名\n",
    "    #                 'ftype':file['matnm'],                 #  文件所属类型   \n",
    "    #                 'fphynm':file['dfphynm'],              #  文件唯一识别名\n",
    "    #                 'ftitle':file['dftitle'],              #  文件标题\n",
    "    #                 'fstatus':file['type'],                #  文件所属环节\n",
    "    #                 'fdate':file['ddt'],                   #  文件日期\n",
    "    #                 'fpath':file['dfpth'],                 #  文件地址\n",
    "    #                 'fext':file['dfext'],                  #  文件后缀\n",
    "    #                 'other':''} \n",
    "    #         material.append(temp_dict)\n",
    "    #     cleaned_dict[value] = material\n",
    "    disclosureMaterial = []\n",
    "    responseAttachment = []\n",
    "    meetingAttachment = []\n",
    "    terminationAttachment = []\n",
    "    registrationAttachment = []\n",
    "\n",
    "    for file in raw_data['release']:\n",
    "\n",
    "\n",
    "        temp_dict =  { 'fname':file['fileTitle'],           #  文件名\n",
    "                    'ftype':'',                 #  文件所属类型   \n",
    "                    'fphynm':file['filename'],              #  文件唯一识别名\n",
    "                    'ftitle':file['fileTitle'],              #  文件标题\n",
    "                    'fstatus':'',                #  文件所属环节\n",
    "                    'fdate':file['publishDate'],                   #  文件日期\n",
    "                    'fpath':file['filePath'],                 #  文件地址\n",
    "                    'fext':'',                  #  文件后缀\n",
    "                    'other':''} \n",
    "        if file['fileType'] == 30:\n",
    "            disclosureMaterial.append(temp_dict)\n",
    "            temp_dict['ftype'] = '招股说明书'\n",
    "            temp_dict['fstatus'] = file['auditStatus']\n",
    "        elif file['fileType'] == 36:\n",
    "            disclosureMaterial.append(temp_dict)\n",
    "            temp_dict['ftype'] = '发行保荐书'\n",
    "            temp_dict['fstatus'] = file['auditStatus']\n",
    "        elif file['fileType'] == 37:\n",
    "            disclosureMaterial.append(temp_dict)\n",
    "            temp_dict['ftype'] = '上市保荐书'\n",
    "            temp_dict['fstatus'] = file['auditStatus']\n",
    "        elif file['fileType'] == 32:\n",
    "            disclosureMaterial.append(temp_dict)\n",
    "            temp_dict['ftype'] = '审计报告'\n",
    "            temp_dict['fstatus'] = file['auditStatus']\n",
    "        elif file['fileType'] == 33:\n",
    "            disclosureMaterial.append(temp_dict)\n",
    "            temp_dict['ftype'] = '法律意见书'\n",
    "            temp_dict['fstatus'] = file['auditStatus']\n",
    "        elif file['fileType'] == 6:\n",
    "            responseAttachment.append(temp_dict)\n",
    "        elif file['fileType'] == 5:\n",
    "            responseAttachment.append(temp_dict)\n",
    "        elif file['fileType'] == 35:\n",
    "            registrationAttachment.append(temp_dict)\n",
    "        elif file['fileType'] == 38:\n",
    "            terminationAttachment.append(temp_dict)\n",
    "\n",
    "\n",
    "    for file in raw_data['result']:\n",
    "        temp_dict =  { 'fname':file['fileTitle'],           #  文件名\n",
    "            'ftype':'',                 #  文件所属类型   \n",
    "            'fphynm':file['fileName'],              #  文件唯一识别名\n",
    "            'ftitle':file['fileTitle'],              #  文件标题\n",
    "            'fstatus':'',                #  文件所属环节\n",
    "            'fdate':file['publishDate'],                   #  文件日期\n",
    "            'fpath':file['filePath'],                 #  文件地址\n",
    "            'fext':'',                  #  文件后缀\n",
    "            'other':''} \n",
    "        if file['fileType'] == 1 or file['fileType'] == 2:\n",
    "            meetingAttachment.append(temp_dict)\n",
    "    cleaned_dict['disclosureMaterial'] = disclosureMaterial\n",
    "    cleaned_dict['responseAttachment'] = responseAttachment\n",
    "    cleaned_dict['meetingAttachment'] = meetingAttachment\n",
    "    cleaned_dict['terminationAttachment'] = terminationAttachment\n",
    "    cleaned_dict['registrationAttachment'] = registrationAttachment\n",
    "\n",
    "    idx = 1\n",
    "    temp2 = []\n",
    "    if raw_data['res'] is not None:\n",
    "        for item in raw_data['res']:\n",
    "            if item['reasonDesc'] != '':\n",
    "                others = { 'order':idx,\n",
    "                    'reason':item['reasonDesc'],\n",
    "                    'date':item['publishDate'],\n",
    "                    'timestamp':item['timesave'].split(' ')[1]}\n",
    "                idx+=1\n",
    "                temp2.append(others)\n",
    "        cleaned_dict['others'] = temp2\n",
    "    else:\n",
    "        cleaned_dict['others'] = ''\n",
    "    return cleaned_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = json.dumps(sz_data,ensure_ascii=False)\n",
    "with open('C:/Users/chen/Desktop/sz.json','w') as file:\n",
    "    file.write(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['terminationNoticeAttachment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = json.loads(sz_data['pjdot'])\n",
    "s =[]\n",
    "temp_dict ={}\n",
    "for i in p.keys():\n",
    "    if i != '-1':\n",
    "        temp_dict= {'status':p[i]['name'],'date':p[i]['startTime'].split(' ')[0],'result':''}\n",
    "        s.append(temp_dict)\n",
    "if '-1' in p.keys():\n",
    "    s[-1]['result'] = p['-1']['name']\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'prjid' in a:\n",
    "    print('yes')\n",
    "else:\n",
    "    print('no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "temp_dict ={'baseInfo':baseInfo,                # 项目基本信息\n",
    "            'disclosureMaterial':[fileConfig],            # 信息披露\n",
    "            'responseAttachment':[fileConfig],            # 问询与回复\n",
    "            'meetingAttachment':[fileConfig],             # 上市委会议公告与结果\n",
    "            'terminationAttachment':[fileConfig],         # 终止审核通知\n",
    "            'registrationAttachment':[fileConfig],       # 注册结果通知\n",
    "            'others':[others]}                        # 其他\n",
    "\n",
    "\n",
    "baseInfo = {'projID':'',                        # 项目id\n",
    "            'cmpName':'',                       # 公司名称\n",
    "            'cmpAbbrname':'',                   # 公司简称\n",
    "            'projType':'',                      # 项目类型\n",
    "            'currStatus':'',                    # 审核状态\n",
    "            'region':'',                        # 所属地区\n",
    "            'csrcCode':'',                      # 所属行业\n",
    "            'acptDate':'',                      # 受理日期\n",
    "            'updtDate':'',                      # 更新日期\n",
    "            'issueAmount':'',                   # 融资金额\n",
    "            'sprInst':'',                       # 保荐机构\n",
    "            'sprInstAbbr':'',                   # 保荐机构简称\n",
    "            'sprRep':'',                        # 保荐代表人\n",
    "            'acctFirm':'',                      # 会计师事务所\n",
    "            'acctSgnt':'',                      # 签字会计师\n",
    "            'lawFirm':'',                       # 律师事务所\n",
    "            'lglSgnt':'',                       # 签字律师\n",
    "            'evalSgnt':'',                      # 签字评估师\n",
    "            'evalInst':'',                      # 评估机构\n",
    "            'projMilestone':[projMilestone],      # 项目里程碑\n",
    "            'auditMarket':''}                   # 所属交易所\n",
    "\n",
    "\n",
    "projMilestone = {'1':{'status':'已受理',\n",
    "                      'time':'',\n",
    "                      'result':''},\n",
    "                '2':{'status':'已问询',\n",
    "                        'result':'',\n",
    "                      'time':''},\n",
    "                '3':{'status':'上市委会议',\n",
    "                    'result':'',\n",
    "                      'time':''},            \n",
    "                '4':{'status':'提交注册',\n",
    "                      'result':'',\n",
    "                      'time':''},            \n",
    "                '5':{'status':'注册结果',\n",
    "                      'result':'',\n",
    "                      'time':''}}          #           #\n",
    "\n",
    "\n",
    "fileConfig = {  'fname':'',                 #  文件名\n",
    "                'ftype':'',                 #  文件所属类型   \n",
    "                'fphynm':'',                #  文件唯一识别名\n",
    "                'ftitle':'',                #  文件标题\n",
    "                'fstatus':'',               #  文件所属环节\n",
    "                'fdate':'',                 #  文件日期\n",
    "                'fpath':'',                 #  文件地址\n",
    "                'fext':'',                  #  文件后缀\n",
    "                'other':''}                 #   (待选)\n",
    "\n",
    "\n",
    "others = {  'index':'',\n",
    "            'reason':'',\n",
    "            'date':'',\n",
    "            'timestamp':''}\n",
    "\n",
    "temp_dict ={'baseInfo':baseInfo,                # 项目基本信息\n",
    "            'disclosureMaterial':[fileConfig],            # 信息披露\n",
    "            'responseAttachment':[fileConfig],            # 问询与回复\n",
    "            'meetingAttachment':[fileConfig],             # 上市委会议公告与结果\n",
    "            'terminationAttachment':[fileConfig],         # 终止审核通知\n",
    "            'registrationAttachment':[fileConfig],       # 注册结果通知\n",
    "            'others':[others]}                        # 其他\n",
    "'''\n",
    "\n",
    "import json\n",
    "\n",
    "def data_process(raw_data):\n",
    "    '''\n",
    "    input : raw_data : dict\n",
    "    '''\n",
    "    if 'prjid' in raw_data.keys():\n",
    "        # this is from sz_exchange\n",
    "        cleaned_data = sz_process(raw_data)\n",
    "    else:\n",
    "        cleaned_data = sh_process(raw_data)\n",
    "    return cleaned_data\n",
    "\n",
    "\n",
    "\n",
    "def sz_process(raw_data):\n",
    "    cleaned_dict = {}\n",
    "    temp = json.loads(raw_data['pjdot'])\n",
    "    \n",
    "    milestone =[]\n",
    "    for i in temp.keys():\n",
    "        if i != '-1' and temp[i]['startTime'] is not None:\n",
    "            temp_dict= {'status':temp[i]['name'],'date':temp[i]['startTime'].split(' ')[0],'result':''}\n",
    "            milestone.append(temp_dict)\n",
    "    if '-1' in temp.keys():\n",
    "        milestone[-1]['result'] = temp['-1']['name']\n",
    "\n",
    "    # clean up info \n",
    "    cleaned_dict['baseInfo'] = {'projID':raw_data['prjid'],                        # 项目id\n",
    "            'cmpName':raw_data['cmpnm'],                       # 公司名称\n",
    "            'cmpAbbrname':raw_data['cmpsnm'],                   # 公司简称\n",
    "            'projType':raw_data['biztyp'],                      # 项目类型\n",
    "            'currStatus':raw_data['prjst'],                    # 审核状态\n",
    "            'region':raw_data['regloc'],                        # 所属地区\n",
    "            'csrcCode':raw_data['csrcind'],                      # 所属行业\n",
    "            'acptDate':raw_data['acptdt'],                      # 受理日期\n",
    "            'updtDate':raw_data['updtdt'],                      # 更新日期\n",
    "            'issueAmount':raw_data['maramt'],                   # 融资金额\n",
    "            'sprInst':raw_data['sprinst'],                       # 保荐机构\n",
    "            'sprInstAbbr':raw_data['sprinsts'],                   # 保荐机构简称\n",
    "            'sprRep':raw_data['sprrep'],                        # 保荐代表人\n",
    "            'acctFirm':raw_data['acctfm'],                      # 会计师事务所\n",
    "            'acctSgnt':raw_data['acctsgnt'],                      # 签字会计师\n",
    "            'lawFirm':raw_data['lawfm'],                       # 律师事务所\n",
    "            'lglSgnt':raw_data['lglsgnt'],                       # 签字律师\n",
    "            'evalSgnt':raw_data['evalinst'],                      # 签字评估师\n",
    "            'evalInst':raw_data['evalsgnt'],                      # 评估机构\n",
    "            'projMilestone':milestone,      # 项目里程碑\n",
    "            'auditMarket':'深圳证券交易所'}                   # 所属交易所\n",
    "\n",
    "    # clean up file\n",
    "    indicator = {'disclosureMaterials':'disclosureMaterial',\n",
    "                'enquiryResponseAttachment':'responseAttachment',\n",
    "                'meetingConclusionAttachment':'meetingAttachment',\n",
    "                'terminationNoticeAttachment':'terminationAttachment',\n",
    "                'registrationResultAttachment':'registrationAttachment'}\n",
    "\n",
    "    for key,value in indicator.items():\n",
    "        material =[]\n",
    "        for file in raw_data[key]:\n",
    "            temp_dict =  { 'fname':file['dfnm'],           #  文件名\n",
    "                    'ftype':file['matnm'],                 #  文件所属类型   \n",
    "                    'fphynm':file['dfphynm'],              #  文件唯一识别名\n",
    "                    'ftitle':file['dftitle'],              #  文件标题\n",
    "                    'fstatus':file['type'],                #  文件所属环节\n",
    "                    'fdate':file['ddt'],                   #  文件日期\n",
    "                    'fpath':file['dfpth'],                 #  文件地址\n",
    "                    'fext':file['dfext'],                  #  文件后缀\n",
    "                    'other':''} \n",
    "            material.append(temp_dict)\n",
    "        cleaned_dict[value] = material\n",
    "\n",
    "    # clean up others \n",
    "    idx = 1\n",
    "    temp2 = []\n",
    "    if raw_data['others'] is not None:\n",
    "        for item in raw_data['others']:\n",
    "\n",
    "            others = {  'order':idx,\n",
    "                'reason':list(item.values())[0].split()[0],\n",
    "                'date':list(item.keys())[0].split()[0],\n",
    "                'timestamp':list(item.keys())[0].split()[1]}\n",
    "            idx+=1\n",
    "            temp2.append(others)\n",
    "        cleaned_dict['others'] = temp2\n",
    "    else:\n",
    "        cleaned_dict['others'] = ''\n",
    "    return cleaned_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r'C:\\Users\\chen\\Desktop\\IPO_info\\三生国健药业（上海）股份有限公司\\clean_info.pkl'\n",
    "sz_data = load_pickle(data_path)\n",
    "# sh_process(sz_data)\n",
    "# sz_process(sz_data)\n",
    "sz_data['baseInfo']['currStatus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('更新日期',ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "listOfFiles = list()\n",
    "for (dirpath, dirnames, filenames) in os.walk(os.getcwd()):\n",
    "    listOfFiles += [os.path.join(dirpath, file) for file in filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "listOfFiles = list()\n",
    "\n",
    "d = 'C:/Users/chen/Desktop/IPO_info/data/IPO/'\n",
    "for (dirpath, dirnames, filenames) in os.walk(d):\n",
    "    listOfFiles += [os.path.join(dirpath, file) for file in filenames]\n",
    "from pathlib import Path\n",
    "for i in listOfFiles:\n",
    "    i = str(Path(i))\n",
    "\n",
    "    if i.endswith('.pkl'):\n",
    "        os.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in listOfFiles[7:]:\n",
    "    if i.endswith('.pkl'):\n",
    "        print(i)\n",
    "        raw_data = load_pickle(i)\n",
    "        cleaned_data = data_process(raw_data)\n",
    "        save_obj(cleaned_data,os.path.dirname(i),'clean_info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "##保存文件\n",
    "fileName = 'C:/Users/chen/Desktop/hhh.csv'\n",
    "with open(fileName,\"w\") as csv_file:\n",
    "\twriter=csv.writer(csv_file)\n",
    "\tfor key,value in sh1.items():\n",
    "\t\twriter.writerow([key,value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sh1 = data_process(sz_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_list = load_pickle('C:/Users/chen/Desktop/IPO_info/sh_index.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(proj_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   序号      交易所             发行人全称  ...       律师事务所        更新日期        受理日期\n",
       "0   1  深圳证券交易所       万凯新材料股份有限公司  ...  北京市金杜律师事务所   2021/1/18  2020/12/18\n",
       "1   2  深圳证券交易所        万香科技股份有限公司  ...  北京市中伦律师事务所  2020/12/25  2020/12/25\n",
       "2   3  深圳证券交易所  三博脑科医院管理集团股份有限公司  ...  北京市中伦律师事务所  2020/12/30  2020/12/30\n",
       "3   4  深圳证券交易所      三友联众集团股份有限公司  ...  北京市中伦律师事务所   2020/12/9    2020/7/1\n",
       "4   5  深圳证券交易所      三河同飞制冷股份有限公司  ...  北京市环球律师事务所   2020/12/9    2020/7/6\n",
       "\n",
       "[5 rows x 11 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>序号</th>\n      <th>交易所</th>\n      <th>发行人全称</th>\n      <th>审核状态</th>\n      <th>注册地</th>\n      <th>行业</th>\n      <th>保荐机构</th>\n      <th>会计师事务所</th>\n      <th>律师事务所</th>\n      <th>更新日期</th>\n      <th>受理日期</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>1</td>\n      <td>深圳证券交易所</td>\n      <td>万凯新材料股份有限公司</td>\n      <td>已问询</td>\n      <td>浙江</td>\n      <td>化学原料和化学制品制造业</td>\n      <td>中国国际金融股份有限公司</td>\n      <td>中汇会计师事务所（特殊普通合伙）</td>\n      <td>北京市金杜律师事务所</td>\n      <td>2021/1/18</td>\n      <td>2020/12/18</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>2</td>\n      <td>深圳证券交易所</td>\n      <td>万香科技股份有限公司</td>\n      <td>已受理</td>\n      <td>江苏</td>\n      <td>化学原料和化学制品制造业</td>\n      <td>民生证券股份有限公司</td>\n      <td>天职国际会计师事务所（特殊普通合伙）</td>\n      <td>北京市中伦律师事务所</td>\n      <td>2020/12/25</td>\n      <td>2020/12/25</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>3</td>\n      <td>深圳证券交易所</td>\n      <td>三博脑科医院管理集团股份有限公司</td>\n      <td>已受理</td>\n      <td>北京</td>\n      <td>卫生</td>\n      <td>中信证券股份有限公司</td>\n      <td>立信会计师事务所（特殊普通合伙）</td>\n      <td>北京市中伦律师事务所</td>\n      <td>2020/12/30</td>\n      <td>2020/12/30</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>4</td>\n      <td>深圳证券交易所</td>\n      <td>三友联众集团股份有限公司</td>\n      <td>注册生效</td>\n      <td>广东</td>\n      <td>电气机械和器材制造业</td>\n      <td>信达证券股份有限公司</td>\n      <td>天健会计师事务所（特殊普通合伙）</td>\n      <td>北京市中伦律师事务所</td>\n      <td>2020/12/9</td>\n      <td>2020/7/1</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>5</td>\n      <td>深圳证券交易所</td>\n      <td>三河同飞制冷股份有限公司</td>\n      <td>上市委会议通过</td>\n      <td>河北</td>\n      <td>通用设备制造业</td>\n      <td>中天国富证券有限公司</td>\n      <td>天健会计师事务所（特殊普通合伙）</td>\n      <td>北京市环球律师事务所</td>\n      <td>2020/12/9</td>\n      <td>2020/7/6</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# from IPython.display import HTML\n",
    "df = pd.read_csv('C:/Users/chen/Desktop/IPO_info/IPO汇总.csv')\n",
    "# df['发行人全称'] = df['发行人全称'].apply(lambda x: '<a href=\"http://example.com/{0}\">{}</a>'.format(x,x)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<email.mime.text.MIMEText at 0x1ec582a8f88>"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "from email.mime.text import MIMEText\n",
    "message_start = f\"\"\"\n",
    "<head>\n",
    "  <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\n",
    "  <title>Report for hhh</title>\"\"\"\n",
    "message_style = \"\"\"\n",
    "  <style type=\"text/css\" media=\"screen\">\n",
    "    #customers {\n",
    "      font-family: \"Trebuchet MS\", Arial, Helvetica, sans-serif;\n",
    "      font-size: 12px;\n",
    "      border-collapse: collapse;\n",
    "      width: 100%;\n",
    "    }\n",
    "\n",
    "    #customers td, #customers th {\n",
    "      border: 1px solid #ddd;\n",
    "      padding: 8px;\n",
    "    }\n",
    "\n",
    "    #customers tr:nth-child(even){background-color: #f2f2f2;}\n",
    "\n",
    "    #customers tr:hover {background-color: #ddd;}\n",
    "\n",
    "    #customers th {\n",
    "      padding-top: 12px;\n",
    "      padding-bottom: 12px;\n",
    "      text-align: left;\n",
    "      background-color: #4CAF50;\n",
    "      color: white;\n",
    "    }\n",
    "  </style>\n",
    "</head>\n",
    "<body>\n",
    "\"\"\"\n",
    "message_body = df.to_html(index=False, table_id=\"customers\") #set table_id to your css style name\n",
    "message_end = \"\"\"</body>\"\"\"\n",
    "messages = (message_start + message_style + message_body + message_end)\n",
    "part = MIMEText(messages, 'html')  # create MIMEText\n",
    "# messages .attach(part)  \n",
    "part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['Unnamed: 0']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('C:/Users/chen/Desktop/hhhh.csv',index=False,encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_list_new = index_getter('ipo')\n",
    "# proj_list_new = index_getter()\n",
    "proj_list_old = load_pickle('C:/Users/chen/Desktop/IPO_info/saved_config/sz_index.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'adb'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-f902a60dd634>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mload_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'adb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-1-b9f378e500ca>\u001b[0m in \u001b[0;36mload_pickle\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mload_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'adb'"
     ]
    }
   ],
   "source": [
    "load_pickle('adb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('哈尔滨森鹰窗业股份有限公司', '2020-12-29')"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "proj_list_old[227]['cmpnm'],proj_list_old[227]['updtdt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "227"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "idx = next((index for (index, d) in enumerate(proj_list_old) if d[\"cmpnm\"] == \"哈尔滨森鹰窗业股份有限公司\"), None)\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('新乡天力锂能股份有限公司', '2021-01-20')"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "proj_list_old[0]['cmpnm'],proj_list_old[0]['updtdt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "idx = next((index for (index, d) in enumerate(proj_list_new) if d[\"cmpnm\"] == \"新乡天力锂能股份有限公司\"), None)\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ues\n"
     ]
    }
   ],
   "source": [
    "if proj_list_new[52] == proj_list_old[0]:\n",
    "    print('ues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "idx = next((index for (index, d) in enumerate(proj_list_new) if d[\"updtdt\"] == '2021-01-24'), None)\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'2021-01-25'"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "datetime.today().strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 227\n1 261\n2 258\n3 430\n4 259\n5 246\n"
     ]
    }
   ],
   "source": [
    "# datetime.today().strftime('%Y-%m-%d')\n",
    "updated_idx = [index for (index, d) in enumerate(proj_list_new) if d[\"updtdt\"] == '2021-01-24']\n",
    "for new_idx in updated_idx:\n",
    "    # name,projid = proj_list_new[i]['cmpnm'],proj_list_new[i]['prjid']\n",
    "    # old_idx = next((index for (index, d) in enumerate(proj_list_old) if d[\"cmpnm\"] == name), None)\n",
    "    # if old_idx is not None:\n",
    "    # # for key, value in proj_list_new[i].items():\n",
    "    # #     if proj_list_old[old_index][key] != value:\n",
    "    # #         print(key,value,proj_list_old[old_index][key])\n",
    "    # if proj_list_new[new_idx]['prjst'] != proj_list_old[old_idx]['prjst']:\n",
    "    raw_data = data_getter(proj_list_new[new_idx]['prjid'])\n",
    "    cleaned_data = data_process(raw_data)\n",
    "    directory = os.getcwd()+'/data/'+cleaned_data['prjType'] + '/' + cleaned_data['prjName']\n",
    "    save_obj(cleaned_data, directory +'/clean_info')\n",
    "    print('company:', os.path.dirname(i),'is updated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'3': 3}\n"
     ]
    }
   ],
   "source": [
    "a = [{'1':1},{'2':2},{'3':3}]\n",
    "b = [{'1':1},{'2':2},{'3':4}]\n",
    "for i in a:\n",
    "    if i not in b:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dfba\n"
     ]
    }
   ],
   "source": [
    "\n",
    "a =next((index for (index, d) in enumerate(proj_list_old) if d[\"cmpnm\"] == 'ff'),None)\n",
    "if a is not None:\n",
    "    print('dd')\n",
    "else:\n",
    "    print('dfba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pickle\n",
    "def load_pickle(path_to_file):\n",
    "    with open(path_to_file, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    return data\n",
    "def load_template(template_path):\n",
    "    with open(template_path, 'r', encoding='utf-8') as f:\n",
    "        soup = BeautifulSoup(f.read(),'html.parser')\n",
    "    return soup\n",
    "soup = load_template('C:/Users/chen/Desktop/测试网页/创业板发行上市审核信息公开网站-IPO.html')\n",
    "allStocksInfo = load_pickle('C:/Users/chen/Desktop/IPO_info/saved_config/IPO_stocksInfo.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempsoup = soup.find(attrs={'class':'projectdynamic-tbody-con'})\n",
    "i = 0\n",
    "for stock in allStocksInfo[:10]:\n",
    "    i+=1\n",
    "    e = stock['baseInfo']\n",
    "    te = '''<tr>\n",
    "            <td class=\"text-center\">{}</td>                           \n",
    "            <td><a target=\"_blank\" href=\"{}\">{} </a></td>             \n",
    "            <td><span class=\"span-a-style\">{}</span></td>             \n",
    "            <td><span class=\"span-a-style\">{}</span></td>             \n",
    "            <td><span class=\"span-a-style\">{}</span></td>            \n",
    "            <td>\n",
    "                <span class=\"span-a-style\" >{}</span>                                   \n",
    "            </td>\n",
    "            <td><span class=\"span-a-style\">{}</span></td>             \n",
    "            <td><span class=\"span-a-style\">{}</span></td>             \n",
    "            <td class=\"text-center\">{}</td>                           \n",
    "            <td class=\"text-center\">{}</td>                          \n",
    "            </tr>\n",
    "    '''.format(str(i),'./data/IPO/'+e['cmpName']+'/'+e['cmpName']+'.html',e['cmpName'],e['currStatus'],e['region'],e['csrcCode'],e['sprInst'],e['lawFirm'],e['acctFirm'],e['updtDate'],e['acptDate'])\n",
    "    # tempsoup = soup.find(attrs={'class':'projectdynamic-tbody-cond'})\n",
    "    tempsoup.append(BeautifulSoup(te,'html.parser'))\n",
    "\n",
    "# def table_element(element_dict):\n",
    "#     e = stock['baseInfo']\n",
    "#     te = '''\n",
    "#     <tr>\n",
    "#             <td class=\"text-center\">{}</td>                           \n",
    "#             <td><a target=\"_blank\" href=\"{}\">{} </a></td>             \n",
    "#             <td><span class=\"span-a-style\">{}</span></td>             \n",
    "#             <td><span class=\"span-a-style\">{}</span></td>             \n",
    "#             <td><span class=\"span-a-style\">{}}</span></td>            \n",
    "#             <td>\n",
    "#                 <span class=\"span-a-style\" >{}</span>                \n",
    "                                \n",
    "#             </td>\n",
    "#             <td><span class=\"span-a-style\">{}</span></td>             \n",
    "#             <td><span class=\"span-a-style\">{}</span></td>             \n",
    "#             <td class=\"text-center\">{}</td>                          \n",
    "#             <td class=\"text-center\">{}</td>                           \n",
    "#             </tr>\n",
    "#     '''.format('1','./data/IPO/'+e['cmpName']+'/'+e['cmpName']+'.html',e['cmpName'],e['currStatus'],e['region'],e['csrcCode'],e['sprInst'],e['lawFirm'],e['acctFirm'],e['updtDate'],e['acptDate'])\n",
    "#     return table_elememt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_html(soup,directory):\n",
    "    # saved_path = r'C:\\Users\\chen\\Desktop\\测试网页' +'\\\\'+ data['baseInfo']['cmpName']+ '.html'\n",
    "    \n",
    "    with open (directory,\"w\", encoding='utf-8') as f:\n",
    "    #   写文件用bytes而不是str，所以要转码  \n",
    "        f.write(str(soup))\n",
    "\n",
    "save_html(soup,'C:/Users/chen/Desktop/测试网页/目录.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "' \\n8\\n-\\n6\\n-\\n1\\n7\\n \\n\\n \\n\\n \\n\\n2,174.59\\n\\n6,883.00\\n\\n\\n13,217.99\\n\\n7,205.71\\n\\n\\n44.59\\n\\n4,736.18\\n\\n11,278.48\\n\\n6,304.61\\n\\n\\n9,603\\n\\n10,018\\n\\n19,163\\n\\n4,235\\n\\n\\n \\n\\n\\n\\n\\n\\n5.05\\n\\n \\n\\n \\n\\n1\\n\\n\\n\\n\\n \\n\\n2\\n\\n\\nKÂNlAÈ˙â?SE¤˝ó˘Õ4Á> AË*üˇ\\\\Nq!8Nq\\n\\n\\n\\n \\n\\n3\\n\\n\\n\\n12%\\n\\n\\n \\n\\n4\\n\\n\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "source": [
    "import PyPDF2\n",
    "\n",
    "# creating an object \n",
    "file = open('C:/Users/chen/Desktop/abc.pdf', 'rb')\n",
    "\n",
    "# creating a pdf reader object\n",
    "fileReader = PyPDF2.PdfFileReader(file)\n",
    "\n",
    "# print the number of pages in pdf file\n",
    "pageObj = fileReader.getPage(16)\n",
    "pageObj.extractText()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pdfplumber'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-84-ad7351ffe0f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpdfplumber\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mpdffile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'C:/Users/chen/Desktop/abc.pdf'\u001b[0m     \u001b[1;31m#pdf檔路徑及檔名\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpdfplumber\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpdffile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mp0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pdfplumber'"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import pdfplumber\n",
    "pdffile='C:/Users/chen/Desktop/abc.pdf'     #pdf檔路徑及檔名\n",
    "pdf = pdfplumber.open(pdffile)\n",
    "p0 = pdf.pages[0]\n",
    "text=p0.extract_text()       #讀文字\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "\n",
    "from scrapy.linkextractors import LinkExtractor\n",
    "\n",
    "from scrapy.spiders import CrawlSpider, Rule\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "class CfSpider(CrawlSpider):\n",
    "\n",
    "    name = 'cf'\n",
    "\n",
    "    allowed_domains = ['csrc.gov.cn']\n",
    "\n",
    "    start_urls = ['http://www.csrc.gov.cn/pub/zjhpublic/832/index_7401.htm']\n",
    "\n",
    "    rules = (\n",
    "        Rule(LinkExtractor(allow=r'/G\\d+/\\d+/t\\d+_\\d+\\.htm'),\n",
    "             callback='parse_item'),\n",
    "\n",
    "        # Rule(LinkExtractor(allow=r'/3300/3313/index_7401_.*?\\.htm'),follow=True), # 不起作用，所以重写了start_requests\n",
    "    )\n",
    "\n",
    "    def start_requests(self):\n",
    "\n",
    "        current_page = 0\n",
    "\n",
    "        while current_page < 67:\n",
    "\n",
    "            if current_page == 0:\n",
    "\n",
    "                url = 'http://www.csrc.gov.cn/pub/zjhpublic/832/index_7401'\n",
    "\n",
    "                next_url = url + \".html\"\n",
    "\n",
    "            else:\n",
    "\n",
    "                url = 'http://www.csrc.gov.cn/pub/zjhpublic/3300/3313/index_7401_{}.htm'\n",
    "\n",
    "                next_url = url.format(str(current_page))\n",
    "\n",
    "            yield scrapy.Request(\n",
    "                url=next_url,\n",
    "                callback=self.parse,\n",
    "            )\n",
    "\n",
    "            current_page += 1\n",
    "\n",
    "    def parse_item(self, response):\n",
    "\n",
    "        item = dict()\n",
    "\n",
    "        item[\"title\"] = response.xpath(\n",
    "            \"//span[@id='lTitle']/text()\").extract_first()\n",
    "\n",
    "        item[\"pub_title\"] = re.findall(r\"<span>(20\\d+年\\d{2}月\\d{2}日)</span>\",\n",
    "                                       response.body.decode(), re.S)\n",
    "\n",
    "        item[\"pub_title\"] = item[\"pub_title\"][0] if item[\"pub_title\"] else None\n",
    "\n",
    "        item[\"index_number\"] = response.xpath(\n",
    "            \"//table[@id='headContainer']//tr[1]//td[@colspan='2']//td[1]/text()\"\n",
    "        ).extract_first()\n",
    "\n",
    "        item[\"href\"] = response.url\n",
    "\n",
    "        yield item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<generator object CfSpider.start_requests at 0x000001EC5B47E548>"
      ]
     },
     "metadata": {},
     "execution_count": 87
    }
   ],
   "source": [
    "a = CfSpider()\n",
    "a.start_requests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'Request' object has no attribute 'xpath'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-92-398e990ee6bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_requests\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-86-914c46266066>\u001b[0m in \u001b[0;36mparse_item\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[0mitem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"title\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"//span[@id='lTitle']/text()\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract_first\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"pub_title\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"<span>(20\\d+年\\d{2}月\\d{2}日)</span>\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Request' object has no attribute 'xpath'"
     ]
    }
   ],
   "source": [
    "print(next(a.parse_item((next(a.start_requests())))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'requests' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-94-e30b51dd36ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'/G\\d+/\\d+/t\\d+_\\d+\\.htm'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mstart_urls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'http://www.csrc.gov.cn/pub/zjhpublic/832/index_7401.htm'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequests\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_urls\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mResponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'requests' is not defined"
     ]
    }
   ],
   "source": [
    "re.compile(r'/G\\d+/\\d+/t\\d+_\\d+\\.htm')\n",
    "start_urls = 'http://www.csrc.gov.cn/pub/zjhpublic/832/index_7401.htm'\n",
    "r=requests(start_urls,headers=headers)\n",
    "r.Response"
   ]
  }
 ]
}