{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def load_pickle(path):\n",
    "    with open(path,'rb') as file:\n",
    "        data=pickle.load(file)\n",
    "    return data\n",
    "data_path = r'C:\\Users\\chen\\Desktop\\IPO_info\\万凯新材料股份有限公司\\info.pkl'\n",
    "\n",
    "def save_obj(obj, directory,filename):\n",
    "    with open(directory +'/'+filename + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import json\n",
    "sql_dict = {'info':'SH_XM_LB',\n",
    "            'release':'GP_GPZCZ_SHXXPL',\n",
    "            'status':'GP_GPZCZ_XMDTZTTLB',\n",
    "            'result':'GP_GPZCZ_SSWHYGGJG',\n",
    "            'res':'GP_GPZCZ_XMDTZTYYLB'}\n",
    "\n",
    "    \n",
    "headers = {'header':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.141 Safari/537.36',\n",
    "           'referer': 'https://kcb.sse.com.cn/',\n",
    "           'Accept': '*/*',\n",
    "           'Accept-Encoding': 'gzip, deflate, br',\n",
    "           'Accept-Language': 'zh-CN,zh;q=0.9',\n",
    "           'Connection': 'keep-alive',\n",
    "           'Cookie': 'JSESSIONID=C2EE2264D8056DC8BF3AB0DC23D26171',\n",
    "           'Host': 'query.sse.com.cn'}\n",
    "\n",
    "def url_parser(stockAidotNum,sqltype):\n",
    "    base_url = 'https://query.sse.com.cn/'\n",
    "    url = base_url + 'commonSoaQuery.do?' + 'jsonCallBack=jsonpCallback3373161' '&sqlId=' +sql_dict[sqltype] + '&stockAuditNum=' + stockAidotNum \n",
    "    return url\n",
    "\n",
    "def jsonp_parser(jsonp_str):\n",
    "    try:\n",
    "        return re.search('^[^(]*?\\((.*)\\)[^)]*$', jsonp_str).group(1)\n",
    "    except:\n",
    "        raise ValueError('Invalid JSONP')\n",
    "\n",
    "def data_getter(stockAidotNum):\n",
    "    stock_allInfo = {}\n",
    "    for sqltype in ['info','status','release','result','res']:\n",
    "        url = url_parser(stockAidotNum,sqltype)\n",
    "        rs = requests.get(url,headers=headers)\n",
    "        raw_data = jsonp_parser(rs.text)\n",
    "        data = json.loads(raw_data)['pageHelp']['data']\n",
    "        stock_allInfo[sqltype] = data\n",
    "    return stock_allInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sh_data = data_getter('549')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.1878847502431651"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "import random\n",
    "random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ----------------Test Environment-------------------\n",
    "import requests\n",
    "import re\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.141 Safari/537.36',}\n",
    "        #    'Accept': '*/*',\n",
    "        #    'Accept-Encoding': 'gzip, deflate',\n",
    "        #    'Accept-Language': 'zh-CN,zh;q=0.9',\n",
    "        #    'Connection': 'keep-alive',\n",
    "        #    'Host': 'listing.szse.cn'}\n",
    "import urllib.parse as urlparse\n",
    "from urllib.parse import urlencode\n",
    "def index_getter(projtype):\n",
    "    if projtype == 'ipo':\n",
    "        biztype = 1\n",
    "    elif projtype == 'refinance':\n",
    "        biztype = 2\n",
    "    elif projtype == 'reproperty':\n",
    "        biztype = 3 \n",
    "    else:\n",
    "        print(\"Input error! Please choose the correct type of data\")\n",
    "        return\n",
    "\n",
    "    params = {'bizType':biztype, 'random':random.random(),'pageIndex':0,'pageSize':1000}\n",
    "    base_url = 'http://listing.szse.cn/api/ras/projectrends/query?'\n",
    "    projList_url = base_url + urlencode(params)\n",
    "\n",
    "    r = requests.get(projList_url,headers=headers)\n",
    "    index_list = json.loads(r.text)\n",
    "    #save_obj(index_list['data'], os.getcwd()+'\\\\'+'sz_index'+'_'+projtype)\n",
    "    return index_list['data']\n",
    "\n",
    "def data_getter(prjid):\n",
    "    base_url = 'http://listing.szse.cn/api/ras/projectrends/details?id='\n",
    "    stock_url = base_url + str(prjid)\n",
    "    r = requests.get(stock_url,headers=headers)\n",
    "    stockInfo = json.loads(r.text)['data']\n",
    "    base_path = os.getcwd() \n",
    "    directory = base_path + '\\\\' + stockInfo['cmpnm']\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    # save_obj(stockInfo,directory+'\\\\'+'sz_info')\n",
    "    return stockInfo\n",
    "\n",
    "def file_getter(stockInfo):\n",
    "    base_path = os.getcwd() \n",
    "    directory = base_path + '\\\\' + stockInfo['cmpnm']\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    response = stockInfo['enquiryResponseAttachment']\n",
    "    disclosure = stockInfo['disclosureMaterials']\n",
    "    base_url = 'http://reportdocs.static.szse.cn'\n",
    "    for prj in disclosure:\n",
    "        filePath = prj['dfpth']\n",
    "        filename = directory + '\\\\'+ prj['dfnm']\n",
    "        download_url = base_url + filePath\n",
    "        time.sleep(random.randint(1, 3))\n",
    "        r = requests.get(download_url,headers=headers)\n",
    "        with open(filename,'wb') as f:\n",
    "            f.write(r.content)\n",
    "\n",
    "def save_obj(obj, directory):\n",
    "    with open(directory + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(directory ):\n",
    "    with open( directory + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "proj_list = index_getter('reproperty')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stockInfo = data_getter(proj_list[0]['prjid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "# 上海证券交易所-科创板股票审核网\n",
    "\n",
    "\n",
    "IPO_sqlId = {'info':'SH_XM_LB',\n",
    "            'release':'GP_GPZCZ_SHXXPL',\n",
    "            'status':'GP_GPZCZ_XMDTZTTLB',\n",
    "            'result':'GP_GPZCZ_SSWHYGGJG',\n",
    "            'res':'GP_GPZCZ_XMDTZTYYLB'}\n",
    "\n",
    "refinance_sqlId = {'info':'GP_BGCZ_XMLB',\n",
    "                    'release':'GP_BGCZ_SSWHYGGJG',\n",
    "                    'status':'GP_BGCZ_XMDTZTTLB',\n",
    "                    'result':'',\n",
    "                    'res':''}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "reproperty_sqlId = {'status':'GP_ZRZ_XMDTZTTLB',\n",
    "                    'release':'GP_ZRZ_GGJG',\n",
    "                    'result':'',\n",
    "                    'res':'GP_ZRZ_XMZTYYLB',\n",
    "                    'info':'GP_ZRZ_XMLB'}\n",
    "\n",
    "\n",
    "    \n",
    "headers = {'header':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.141 Safari/537.36',\n",
    "           'referer': 'https://kcb.sse.com.cn/',\n",
    "           'Accept': '*/*',\n",
    "           'Accept-Encoding': 'gzip, deflate, br',\n",
    "           'Accept-Language': 'zh-CN,zh;q=0.9',\n",
    "           'Connection': 'keep-alive',\n",
    "           'Cookie': 'JSESSIONID=A53F3AFE1C4FC9029CDF0AB8305EC4D0',\n",
    "           'Host': 'query.sse.com.cn'}\n",
    "\n",
    "base_url = 'https://query.sse.com.cn/'\n",
    "def url_parser(stockAidotNum,sqltype,projtype):\n",
    "    if projtype == 'ipo':\n",
    "        sqlId = IPO_sqlId[sqltype]\n",
    "    elif projtype == 'refinance':\n",
    "        sqlId = refinance_sqlId[sqltype]\n",
    "\n",
    "    elif projtype == 'reproperty':\n",
    "        sqlId = reproperty_sqlId[sqltype]\n",
    "    if sqlId == '':\n",
    "        return ''\n",
    "    else:\n",
    "        url = base_url + 'commonSoaQuery.do?' + 'jsonCallBack=jsonpCallback28511843' '&sqlId=' + sqlId + '&stockAuditNum=' + stockAidotNum \n",
    "        return url\n",
    "\n",
    "def jsonp_parser(jsonp_str):\n",
    "    try:\n",
    "        return re.search('^[^(]*?\\((.*)\\)[^)]*$', jsonp_str).group(1)\n",
    "    except:\n",
    "        raise ValueError('Invalid JSONP')\n",
    "\n",
    "def data_getter(stockAidotNum,projtype):\n",
    "    base_path = os.getcwd() \n",
    "    \n",
    "\n",
    "    stock_allInfo = {}\n",
    "    for sqltype in ['info','status','release','result','res']:\n",
    "\n",
    "        url = url_parser(stockAidotNum,sqltype,projtype)\n",
    "        if url != '':\n",
    "            rs = requests.get(url,headers=headers)\n",
    "            raw_data = jsonp_parser(rs.text)\n",
    "            data = json.loads(raw_data)['pageHelp']['data']\n",
    "            stock_allInfo[sqltype] = data\n",
    "        else:\n",
    "            stock_allInfo[sqltype] = ''\n",
    "    # directory = base_path+ '\\\\'+stock_allInfo['info'][0]['stockAuditName']\n",
    "    # if not os.path.exists(directory):\n",
    "    #     os.makedirs(directory)\n",
    "    # save_obj(stock_allInfo,directory+'\\\\'+'info')\n",
    "    return stock_allInfo\n",
    "\n",
    "def index_getter(projtype):\n",
    "    if projtype == 'ipo':\n",
    "        index_url = 'https://query.sse.com.cn/statusAction.do?jsonCallBack=jsonpCallback47570&isPagination=true&sqlId=SH_XM_LB&pageHelp.pageSize=1000&offerType=&commitiResult=&registeResult=&csrcCode=&currStatus=&order=updateDate%7Cdesc&keyword=&auditApplyDateBegin=&auditApplyDateEnd=&_=1611139628341'\n",
    "    elif projtype == 'refinance':\n",
    "        index_url = 'https://query.sse.com.cn/bgczStatusAction.do?jsonCallBack=jsonpCallback52431&isPagination=true&sqlId=GP_BGCZ_XMLB&pageHelp.pageSize=1000&offerType=&commitiResult=&registeResult=&csrcCode=&currStatus=&order=updateDate%7Cdesc&keyword=&auditApplyDateBegin=&auditApplyDateEnd=&_=1611139628341'\n",
    "    elif projtype == 'reproperty':\n",
    "        index_url = 'https://query.sse.com.cn/zrzStatusAction.do?jsonCallBack=jsonpCallback89527&isPagination=true&sqlId=GP_ZRZ_XMLB&pageHelp.pageSize=1000&offerType=&commitiResult=&registeResult=&csrcCode=&currStatus=&order=updateDate%7Cdesc&keyword=&auditApplyDateBegin=&auditApplyDateEnd=&_=1611139628341'\n",
    "    \n",
    "\n",
    "    r = requests.get(index_url, headers=headers)\n",
    "\n",
    "    js = jsonp_parser(r.text)\n",
    "    index_list = json.loads(js)['result']\n",
    "\n",
    "    save_obj(index_list, os.getcwd() + '\\\\' + 'sh_index'+'_'+projtype)\n",
    "    return index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa =index_getter('reproperty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'https://query.sse.com.cn/commonSoaQuery.do?jsonCallBack=jsonpCallback28511843&sqlId=GP_ZTZXMLB&stockAuditNum=1000004'"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "data_getter('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'jsonCallBack': 'jsonpCallback28511843',\n",
       " 'success': 'false',\n",
       " 'errorMsg': '找不到配置数据',\n",
       " 'errorType': 'ExceptionInterceptor'}"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sh_process(raw_data):\n",
    "    cleaned_dict = {}\n",
    "    # temp = json.loads(raw_data['pjdot'])\n",
    "    name_list = ['已受理','已问询','上市委会议','提交注册','注册生效']\n",
    "    milestone =[]\n",
    "\n",
    "    for st in raw_data['status']:\n",
    "        commit_result = '通过' if st['commitiResult'] == 1 else ''\n",
    "        temp_dict= {'status':name_list[st['auditStatus']-1],\n",
    "                    'date':st['publishDate'],\n",
    "                    'result':commit_result}\n",
    "        milestone.append(temp_dict)\n",
    "\n",
    "    info = raw_data['info'][0]\n",
    "    sx = info['intermediary'][0]['i_person']\n",
    "    k = [ssx['i_p_personName'] for ssx in sx if ssx['i_p_jobType']==22 or ssx['i_p_jobType']==23]\n",
    "    sprrep = ', '.join(k)\n",
    "    sx = info['intermediary'][1]['i_person']\n",
    "    k = [ssx['i_p_personName'] for ssx in sx if ssx['i_p_jobType']==32 or ssx['i_p_jobType']==33]\n",
    "    acctsgnt = ', '.join(k)\n",
    "    sx = info['intermediary'][2]['i_person']\n",
    "    k = [ssx['i_p_personName'] for ssx in sx if ssx['i_p_jobType']==42 or ssx['i_p_jobType']==43]\n",
    "    lglsgnt = ', '.join(k)\n",
    "    sx = info['intermediary'][3]['i_person']\n",
    "    k = [ssx['i_p_personName'] for ssx in sx if ssx['i_p_jobType']==52 or ssx['i_p_jobType']==53]\n",
    "    evalsgnt = ', '.join(k)\n",
    "    # clean up info \n",
    "    cleaned_dict['baseInfo'] = {'projID':info['stockAuditNum'],                        # 项目id\n",
    "            'cmpName':info['stockIssuer'][0]['s_issueCompanyFullName'],                       # 公司名称\n",
    "            'cmpAbbrname':info['stockIssuer'][0]['s_issueCompanyAbbrName'],                   # 公司简称\n",
    "            'projType':'IPO',                      # 项目类型\n",
    "            'currStatus':name_list[info['currStatus']-1],                    # 审核状态\n",
    "            'region':info['stockIssuer'][0]['s_province'],                        # 所属地区\n",
    "            'csrcCode':info['stockIssuer'][0]['s_csrcCodeDesc'],                      # 所属行业\n",
    "            'acptDate':raw_data['status'][0]['publishDate'],                      # 受理日期\n",
    "            'updtDate':raw_data['status'][-1]['publishDate'],                      # 更新日期\n",
    "            'issueAmount':info['planIssueCapital'],                   # 融资金额\n",
    "            'sprInst':info['intermediary'][0]['i_intermediaryName'],                       # 保荐机构\n",
    "            'sprInstAbbr':info['intermediary'][0]['i_intermediaryAbbrName'],                   # 保荐机构简称\n",
    "            'sprRep':sprrep,                        # 保荐代表人\n",
    "            'acctFirm':info['intermediary'][1]['i_intermediaryName'],                      # 会计师事务所\n",
    "            'acctSgnt':acctsgnt,                      # 签字会计师\n",
    "            'lawFirm':info['intermediary'][2]['i_intermediaryName'],                       # 律师事务所\n",
    "            'lglSgnt':lglsgnt,                       # 签字律师\n",
    "            'evalSgnt':info['intermediary'][3]['i_intermediaryName'],                      # 签字评估师\n",
    "            'evalInst':evalsgnt,                      # 评估机构\n",
    "            'projMilestone':milestone,      # 项目里程碑\n",
    "            'auditMarket':'上海证券交易所'}                   # 所属交易所\n",
    "\n",
    "    # # clean up file\n",
    "    # indicator = {'disclosureMaterials':'disclosureMaterial',\n",
    "    #             'enquiryResponseAttachment':'responseAttachment',\n",
    "    #             'meetingConclusionAttachment':'meetingAttachment',\n",
    "    #             'terminationNoticeAttachment':'terminationAttachment',\n",
    "    #             'registrationResultAttachment':'registrationAttachment'}\n",
    "\n",
    "    # for key,value in indicator.items():\n",
    "    #     material =[]\n",
    "    #     for file in raw_data[key]:\n",
    "    #         temp_dict =  { 'fname':file['dfnm'],           #  文件名\n",
    "    #                 'ftype':file['matnm'],                 #  文件所属类型   \n",
    "    #                 'fphynm':file['dfphynm'],              #  文件唯一识别名\n",
    "    #                 'ftitle':file['dftitle'],              #  文件标题\n",
    "    #                 'fstatus':file['type'],                #  文件所属环节\n",
    "    #                 'fdate':file['ddt'],                   #  文件日期\n",
    "    #                 'fpath':file['dfpth'],                 #  文件地址\n",
    "    #                 'fext':file['dfext'],                  #  文件后缀\n",
    "    #                 'other':''} \n",
    "    #         material.append(temp_dict)\n",
    "    #     cleaned_dict[value] = material\n",
    "    disclosureMaterial = []\n",
    "    responseAttachment = []\n",
    "    meetingAttachment = []\n",
    "    terminationAttachment = []\n",
    "    registrationAttachment = []\n",
    "\n",
    "    for file in raw_data['release']:\n",
    "\n",
    "\n",
    "        temp_dict =  { 'fname':file['fileTitle'],           #  文件名\n",
    "                    'ftype':'',                 #  文件所属类型   \n",
    "                    'fphynm':file['filename'],              #  文件唯一识别名\n",
    "                    'ftitle':file['fileTitle'],              #  文件标题\n",
    "                    'fstatus':'',                #  文件所属环节\n",
    "                    'fdate':file['publishDate'],                   #  文件日期\n",
    "                    'fpath':file['filePath'],                 #  文件地址\n",
    "                    'fext':'',                  #  文件后缀\n",
    "                    'other':''} \n",
    "        if file['fileType'] == 30:\n",
    "            disclosureMaterial.append(temp_dict)\n",
    "            temp_dict['ftype'] = '招股说明书'\n",
    "            temp_dict['fstatus'] = file['auditStatus']\n",
    "        elif file['fileType'] == 36:\n",
    "            disclosureMaterial.append(temp_dict)\n",
    "            temp_dict['ftype'] = '发行保荐书'\n",
    "            temp_dict['fstatus'] = file['auditStatus']\n",
    "        elif file['fileType'] == 37:\n",
    "            disclosureMaterial.append(temp_dict)\n",
    "            temp_dict['ftype'] = '上市保荐书'\n",
    "            temp_dict['fstatus'] = file['auditStatus']\n",
    "        elif file['fileType'] == 32:\n",
    "            disclosureMaterial.append(temp_dict)\n",
    "            temp_dict['ftype'] = '审计报告'\n",
    "            temp_dict['fstatus'] = file['auditStatus']\n",
    "        elif file['fileType'] == 33:\n",
    "            disclosureMaterial.append(temp_dict)\n",
    "            temp_dict['ftype'] = '法律意见书'\n",
    "            temp_dict['fstatus'] = file['auditStatus']\n",
    "        elif file['fileType'] == 6:\n",
    "            responseAttachment.append(temp_dict)\n",
    "        elif file['fileType'] == 5:\n",
    "            responseAttachment.append(temp_dict)\n",
    "        elif file['fileType'] == 35:\n",
    "            registrationAttachment.append(temp_dict)\n",
    "        elif file['fileType'] == 38:\n",
    "            terminationAttachment.append(temp_dict)\n",
    "\n",
    "\n",
    "    for file in raw_data['result']:\n",
    "        temp_dict =  { 'fname':file['fileTitle'],           #  文件名\n",
    "            'ftype':'',                 #  文件所属类型   \n",
    "            'fphynm':file['fileName'],              #  文件唯一识别名\n",
    "            'ftitle':file['fileTitle'],              #  文件标题\n",
    "            'fstatus':'',                #  文件所属环节\n",
    "            'fdate':file['publishDate'],                   #  文件日期\n",
    "            'fpath':file['filePath'],                 #  文件地址\n",
    "            'fext':'',                  #  文件后缀\n",
    "            'other':''} \n",
    "        if file['fileType'] == 1 or file['fileType'] == 2:\n",
    "            meetingAttachment.append(temp_dict)\n",
    "    cleaned_dict['disclosureMaterial'] = disclosureMaterial\n",
    "    cleaned_dict['responseAttachment'] = responseAttachment\n",
    "    cleaned_dict['meetingAttachment'] = meetingAttachment\n",
    "    cleaned_dict['terminationAttachment'] = terminationAttachment\n",
    "    cleaned_dict['registrationAttachment'] = registrationAttachment\n",
    "\n",
    "    idx = 1\n",
    "    temp2 = []\n",
    "    if raw_data['res'] is not None:\n",
    "        for item in raw_data['res']:\n",
    "            if item['reasonDesc'] != '':\n",
    "                others = { 'order':idx,\n",
    "                    'reason':item['reasonDesc'],\n",
    "                    'date':item['publishDate'],\n",
    "                    'timestamp':item['timesave'].split(' ')[1]}\n",
    "                idx+=1\n",
    "                temp2.append(others)\n",
    "        cleaned_dict['others'] = temp2\n",
    "    else:\n",
    "        cleaned_dict['others'] = ''\n",
    "    return cleaned_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = json.dumps(sz_data,ensure_ascii=False)\n",
    "with open('C:/Users/chen/Desktop/sz.json','w') as file:\n",
    "    file.write(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['terminationNoticeAttachment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = json.loads(sz_data['pjdot'])\n",
    "s =[]\n",
    "temp_dict ={}\n",
    "for i in p.keys():\n",
    "    if i != '-1':\n",
    "        temp_dict= {'status':p[i]['name'],'date':p[i]['startTime'].split(' ')[0],'result':''}\n",
    "        s.append(temp_dict)\n",
    "if '-1' in p.keys():\n",
    "    s[-1]['result'] = p['-1']['name']\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'prjid' in a:\n",
    "    print('yes')\n",
    "else:\n",
    "    print('no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "temp_dict ={'baseInfo':baseInfo,                # 项目基本信息\n",
    "            'disclosureMaterial':[fileConfig],            # 信息披露\n",
    "            'responseAttachment':[fileConfig],            # 问询与回复\n",
    "            'meetingAttachment':[fileConfig],             # 上市委会议公告与结果\n",
    "            'terminationAttachment':[fileConfig],         # 终止审核通知\n",
    "            'registrationAttachment':[fileConfig],       # 注册结果通知\n",
    "            'others':[others]}                        # 其他\n",
    "\n",
    "\n",
    "baseInfo = {'projID':'',                        # 项目id\n",
    "            'cmpName':'',                       # 公司名称\n",
    "            'cmpAbbrname':'',                   # 公司简称\n",
    "            'projType':'',                      # 项目类型\n",
    "            'currStatus':'',                    # 审核状态\n",
    "            'region':'',                        # 所属地区\n",
    "            'csrcCode':'',                      # 所属行业\n",
    "            'acptDate':'',                      # 受理日期\n",
    "            'updtDate':'',                      # 更新日期\n",
    "            'issueAmount':'',                   # 融资金额\n",
    "            'sprInst':'',                       # 保荐机构\n",
    "            'sprInstAbbr':'',                   # 保荐机构简称\n",
    "            'sprRep':'',                        # 保荐代表人\n",
    "            'acctFirm':'',                      # 会计师事务所\n",
    "            'acctSgnt':'',                      # 签字会计师\n",
    "            'lawFirm':'',                       # 律师事务所\n",
    "            'lglSgnt':'',                       # 签字律师\n",
    "            'evalSgnt':'',                      # 签字评估师\n",
    "            'evalInst':'',                      # 评估机构\n",
    "            'projMilestone':[projMilestone],      # 项目里程碑\n",
    "            'auditMarket':''}                   # 所属交易所\n",
    "\n",
    "\n",
    "projMilestone = {'1':{'status':'已受理',\n",
    "                      'time':'',\n",
    "                      'result':''},\n",
    "                '2':{'status':'已问询',\n",
    "                        'result':'',\n",
    "                      'time':''},\n",
    "                '3':{'status':'上市委会议',\n",
    "                    'result':'',\n",
    "                      'time':''},            \n",
    "                '4':{'status':'提交注册',\n",
    "                      'result':'',\n",
    "                      'time':''},            \n",
    "                '5':{'status':'注册结果',\n",
    "                      'result':'',\n",
    "                      'time':''}}          #           #\n",
    "\n",
    "\n",
    "fileConfig = {  'fname':'',                 #  文件名\n",
    "                'ftype':'',                 #  文件所属类型   \n",
    "                'fphynm':'',                #  文件唯一识别名\n",
    "                'ftitle':'',                #  文件标题\n",
    "                'fstatus':'',               #  文件所属环节\n",
    "                'fdate':'',                 #  文件日期\n",
    "                'fpath':'',                 #  文件地址\n",
    "                'fext':'',                  #  文件后缀\n",
    "                'other':''}                 #   (待选)\n",
    "\n",
    "\n",
    "others = {  'index':'',\n",
    "            'reason':'',\n",
    "            'date':'',\n",
    "            'timestamp':''}\n",
    "\n",
    "temp_dict ={'baseInfo':baseInfo,                # 项目基本信息\n",
    "            'disclosureMaterial':[fileConfig],            # 信息披露\n",
    "            'responseAttachment':[fileConfig],            # 问询与回复\n",
    "            'meetingAttachment':[fileConfig],             # 上市委会议公告与结果\n",
    "            'terminationAttachment':[fileConfig],         # 终止审核通知\n",
    "            'registrationAttachment':[fileConfig],       # 注册结果通知\n",
    "            'others':[others]}                        # 其他\n",
    "'''\n",
    "\n",
    "import json\n",
    "\n",
    "def data_process(raw_data):\n",
    "    '''\n",
    "    input : raw_data : dict\n",
    "    '''\n",
    "    if 'prjid' in raw_data.keys():\n",
    "        # this is from sz_exchange\n",
    "        cleaned_data = sz_process(raw_data)\n",
    "    else:\n",
    "        cleaned_data = sh_process(raw_data)\n",
    "    return cleaned_data\n",
    "\n",
    "\n",
    "\n",
    "def sz_process(raw_data):\n",
    "    cleaned_dict = {}\n",
    "    temp = json.loads(raw_data['pjdot'])\n",
    "    \n",
    "    milestone =[]\n",
    "    for i in temp.keys():\n",
    "        if i != '-1' and temp[i]['startTime'] is not None:\n",
    "            temp_dict= {'status':temp[i]['name'],'date':temp[i]['startTime'].split(' ')[0],'result':''}\n",
    "            milestone.append(temp_dict)\n",
    "    if '-1' in temp.keys():\n",
    "        milestone[-1]['result'] = temp['-1']['name']\n",
    "\n",
    "    # clean up info \n",
    "    cleaned_dict['baseInfo'] = {'projID':raw_data['prjid'],                        # 项目id\n",
    "            'cmpName':raw_data['cmpnm'],                       # 公司名称\n",
    "            'cmpAbbrname':raw_data['cmpsnm'],                   # 公司简称\n",
    "            'projType':raw_data['biztyp'],                      # 项目类型\n",
    "            'currStatus':raw_data['prjst'],                    # 审核状态\n",
    "            'region':raw_data['regloc'],                        # 所属地区\n",
    "            'csrcCode':raw_data['csrcind'],                      # 所属行业\n",
    "            'acptDate':raw_data['acptdt'],                      # 受理日期\n",
    "            'updtDate':raw_data['updtdt'],                      # 更新日期\n",
    "            'issueAmount':raw_data['maramt'],                   # 融资金额\n",
    "            'sprInst':raw_data['sprinst'],                       # 保荐机构\n",
    "            'sprInstAbbr':raw_data['sprinsts'],                   # 保荐机构简称\n",
    "            'sprRep':raw_data['sprrep'],                        # 保荐代表人\n",
    "            'acctFirm':raw_data['acctfm'],                      # 会计师事务所\n",
    "            'acctSgnt':raw_data['acctsgnt'],                      # 签字会计师\n",
    "            'lawFirm':raw_data['lawfm'],                       # 律师事务所\n",
    "            'lglSgnt':raw_data['lglsgnt'],                       # 签字律师\n",
    "            'evalSgnt':raw_data['evalinst'],                      # 签字评估师\n",
    "            'evalInst':raw_data['evalsgnt'],                      # 评估机构\n",
    "            'projMilestone':milestone,      # 项目里程碑\n",
    "            'auditMarket':'深圳证券交易所'}                   # 所属交易所\n",
    "\n",
    "    # clean up file\n",
    "    indicator = {'disclosureMaterials':'disclosureMaterial',\n",
    "                'enquiryResponseAttachment':'responseAttachment',\n",
    "                'meetingConclusionAttachment':'meetingAttachment',\n",
    "                'terminationNoticeAttachment':'terminationAttachment',\n",
    "                'registrationResultAttachment':'registrationAttachment'}\n",
    "\n",
    "    for key,value in indicator.items():\n",
    "        material =[]\n",
    "        for file in raw_data[key]:\n",
    "            temp_dict =  { 'fname':file['dfnm'],           #  文件名\n",
    "                    'ftype':file['matnm'],                 #  文件所属类型   \n",
    "                    'fphynm':file['dfphynm'],              #  文件唯一识别名\n",
    "                    'ftitle':file['dftitle'],              #  文件标题\n",
    "                    'fstatus':file['type'],                #  文件所属环节\n",
    "                    'fdate':file['ddt'],                   #  文件日期\n",
    "                    'fpath':file['dfpth'],                 #  文件地址\n",
    "                    'fext':file['dfext'],                  #  文件后缀\n",
    "                    'other':''} \n",
    "            material.append(temp_dict)\n",
    "        cleaned_dict[value] = material\n",
    "\n",
    "    # clean up others \n",
    "    idx = 1\n",
    "    temp2 = []\n",
    "    if raw_data['others'] is not None:\n",
    "        for item in raw_data['others']:\n",
    "\n",
    "            others = {  'order':idx,\n",
    "                'reason':list(item.values())[0].split()[0],\n",
    "                'date':list(item.keys())[0].split()[0],\n",
    "                'timestamp':list(item.keys())[0].split()[1]}\n",
    "            idx+=1\n",
    "            temp2.append(others)\n",
    "        cleaned_dict['others'] = temp2\n",
    "    else:\n",
    "        cleaned_dict['others'] = ''\n",
    "    return cleaned_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r'C:\\Users\\chen\\Desktop\\IPO_info\\三生国健药业（上海）股份有限公司\\clean_info.pkl'\n",
    "sz_data = load_pickle(data_path)\n",
    "# sh_process(sz_data)\n",
    "# sz_process(sz_data)\n",
    "sz_data['baseInfo']['currStatus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('更新日期',ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "listOfFiles = list()\n",
    "for (dirpath, dirnames, filenames) in os.walk(os.getcwd()):\n",
    "    listOfFiles += [os.path.join(dirpath, file) for file in filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 'C:/Users/chen/Desktop/IPO_info'\n",
    "for (dirpath, dirnames, filenames) in os.walk(d):\n",
    "    listOfFiles += [os.path.join(dirpath, file) for file in filenames]\n",
    "from pathlib import Path\n",
    "for i in listOfFiles[:5]:\n",
    "    i = str(Path(i))\n",
    "\n",
    "    if i.endswith('.pdf'):\n",
    "        os.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in listOfFiles[7:]:\n",
    "    if i.endswith('.pkl'):\n",
    "        print(i)\n",
    "        raw_data = load_pickle(i)\n",
    "        cleaned_data = data_process(raw_data)\n",
    "        save_obj(cleaned_data,os.path.dirname(i),'clean_info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "##保存文件\n",
    "fileName = 'C:/Users/chen/Desktop/hhh.csv'\n",
    "with open(fileName,\"w\") as csv_file:\n",
    "\twriter=csv.writer(csv_file)\n",
    "\tfor key,value in sh1.items():\n",
    "\t\twriter.writerow([key,value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sh1 = data_process(sz_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_list = load_pickle('C:/Users/chen/Desktop/IPO_info/sh_index.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(proj_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import HTML\n",
    "df = pd.read_csv('C:/Users/chen/Desktop/IPO_info/IPO汇总.csv')\n",
    "df['发行人全称'] = df['发行人全称'].apply(lambda x: '<a href=\"http://example.com/{0}\">{}</a>'.format(x,x)\n",
    "HTML(df.to_html(escape=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['Unnamed: 0']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('C:/Users/chen/Desktop/hhhh.csv',index=False,encoding='utf-8-sig')"
   ]
  }
 ]
}